<!DOCTYPE html>
<html lang="fr">

<head>
    <meta charset="UTF-8">
    <title>Protocole de Benchmark - Assistant FAQ</title>
    <link href="https://fonts.googleapis.com/css2?family=Outfit:wght@300;400;600;800&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Outfit', sans-serif;
            padding: 2rem;
            max-width: 800px;
            margin: 0 auto;
            color: #333;
        }

        h1 {
            color: #2c3e50;
            text-align: center;
            border-bottom: 2px solid #667eea;
            padding-bottom: 1rem;
        }

        h2 {
            color: #667eea;
            margin-top: 2rem;
        }

        h3 {
            color: #2c3e50;
            margin-top: 1.5rem;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 1rem;
        }

        th,
        td {
            border: 1px solid #ddd;
            padding: 0.8rem;
            text-align: left;
        }

        th {
            background-color: #f8f9fa;
            color: #667eea;
        }

        ul {
            margin-top: 0.5rem;
            line-height: 1.6;
        }

        .highlight {
            background: #f0f4ff;
            padding: 1rem;
            border-radius: 8px;
            margin-top: 1rem;
        }
    </style>
</head>

<body>

    <h1>Protocole de Benchmark</h1>
    <p>Ce document définit la méthodologie pour évaluer et comparer les 3 stratégies d'Assistant FAQ.</p>

    <h2>1. Critères d'Évaluation</h2>
    <table>
        <tr>
            <th>Critère</th>
            <th>Description</th>
            <th>Poids</th>
        </tr>
        <tr>
            <td><strong>Exactitude</strong></td>
            <td>La réponse est-elle factuellement correcte ? (Note 1-5)</td>
            <td>40%</td>
        </tr>
        <tr>
            <td><strong>Pertinence</strong></td>
            <td>La réponse est-elle utile pour l'usager ?</td>
            <td>30%</td>
        </tr>
        <tr>
            <td><strong>Hallucinations</strong></td>
            <td>L'IA a-t-elle inventé des informations ? (0/1)</td>
            <td>20%</td>
        </tr>
        <tr>
            <td><strong>Latence</strong></td>
            <td>Temps de réponse (ms)</td>
            <td>10%</td>
        </tr>
    </table>

    <h2>2. Jeu de Données (Golden Set)</h2>
    <div class="highlight">
        <p><strong>Total : 25 Questions de Test</strong></p>
        <ul>
            <li>10 Questions Simples (Horaires, Adresses)</li>
            <li>10 Questions Complexes (Aides, Démarches)</li>
            <li>5 Questions Hors Sujet (Test des garde-fous)</li>
        </ul>
    </div>

    <h2>3. Outils & Métriques</h2>
    <p>Le benchmark sera réalisé à l'aide des scripts Python du dossier <code>src/</code>.</p>
    <ul>
        <li><strong>Calcul de similarité :</strong> SBERT (Cosine Similarity).</li>
        <li><strong>Validation humaine :</strong> Grille d'évaluation (Excel/PDF).</li>
    </ul>

    <h2>4. Procédure</h2>
    <ol>
        <li>Lancer le script de test pour la Stratégie A.</li>
        <li>Noter les résultats dans la Grille.</li>
        <li>Répéter pour B et C.</li>
        <li>Synthétiser les scores dans le Rapport Final.</li>
    </ol>

</body>

</html>