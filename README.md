# Assistant FAQ Intelligent pour CollectivitÃ© Territoriale

## ğŸ“‹ Description

Projet de dÃ©veloppement et d'Ã©valuation de **3 stratÃ©gies d'intelligence artificielle** pour rÃ©pondre automatiquement aux questions frÃ©quentes des citoyens d'une communautÃ© de communes.

### Les 3 StratÃ©gies

| StratÃ©gie | Description | Avantages | InconvÃ©nients |
|-----------|-------------|-----------|---------------|
| **A - LLM Seul** | Utilise uniquement Llama 3 avec un prompt systÃ¨me | Simple, rapide | Risque d'hallucinations |
| **B - RAG** | Recherche sÃ©mantique + gÃ©nÃ©ration (Embeddings + LLM) | Fiable, sourcÃ© | Plus complexe, latence |
| **C - Extractif** | Extraction de rÃ©ponse exacte (Roberta-base-squad2) | PrÃ©cis, pas d'hallucination | Rigide, moins naturel |

---

## ğŸš€ Installation

### PrÃ©requis

- **Python 3.9+**
- Compte **Hugging Face** (gratuit) avec token API
- Connexion Internet (pour tÃ©lÃ©charger les modÃ¨les)

### Ã‰tapes

1. **Cloner le projet** (ou tÃ©lÃ©charger le dossier)

2. **Installer les dÃ©pendances**
   ```bash
   pip3 install -r requirements.txt
   ```

3. **Configurer le token Hugging Face**
   
   CrÃ©ez un fichier `.env` Ã  la racine du projet :
   ```
   HF_TOKEN=votre_token_ici
   ```
   
   Pour obtenir votre token : [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)

---

## ğŸ“‚ Structure du Projet

```
.
â”œâ”€â”€ README.md                    # Ce fichier
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â”œâ”€â”€ .env                         # Token API (Ã  crÃ©er)
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ faq_base.json       # Base de 70 questions-rÃ©ponses
â”‚       â””â”€â”€ golden_set.json     # 30 questions de test pour benchmark
â”‚
â”œâ”€â”€ docs/                        # Documentation du projet
â”‚   â”œâ”€â”€ benchmark/               # Grilles d'Ã©valuation
â”‚   â”‚   â”œâ”€â”€ GRILLE_EVALUATION.md
â”‚   â”‚   â””â”€â”€ GRILLE_EVALUATION.pdf
â”‚   â”‚
â”‚   â”œâ”€â”€ day_1/                   # Livrables Jour 1
â”‚   â”‚   â”œâ”€â”€ note_de_cadrage.html
â”‚   â”‚   â”œâ”€â”€ note_de_cadrage.pdf
â”‚   â”‚   â”œâ”€â”€ rapport_veille_technique.html
â”‚   â”‚   â””â”€â”€ rapport_veille_technique.pdf
â”‚   â”‚
â”‚   â””â”€â”€ day_2/                   # Livrables Jour 2
â”‚       â”œâ”€â”€ protocole_benchmark.html
â”‚       â”œâ”€â”€ protocole_benchmark.pdf
â”‚       â”œâ”€â”€ grille_evaluation.html
â”‚       â””â”€â”€ grille_evaluation.pdf
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ outils/
    â”‚   â”œâ”€â”€ client_ia.py        # Configuration client Hugging Face
    â”‚   â””â”€â”€ chargement_donnees.py
    â”‚
    â””â”€â”€ strategies/
        â”œâ”€â”€ strategie_a_llm_seul.py    # StratÃ©gie A
        â”œâ”€â”€ strategie_b_rag.py         # StratÃ©gie B (RAG)
        â””â”€â”€ strategie_c_extractif.py   # StratÃ©gie C (Ã  venir)
```

---

## ğŸ¯ Utilisation

### Tester la StratÃ©gie A (LLM Seul)

```bash
cd src/strategies
python3 strategie_a_llm_seul.py
```

**Exemple de sortie :**
```
--- StratÃ©gie A : LLM Seul (meta-llama/Meta-Llama-3-8B-Instruct) ---
Question : quel Ã¢ge as-tu ?
RÃ©ponse : Je ne suis pas habilitÃ© Ã  rÃ©pondre Ã  ce genre de question.
```

### Tester la StratÃ©gie B (RAG)

```bash
cd src/strategies
python3 strategie_b_rag.py
```

**Exemple de sortie :**
```
Chargement du modÃ¨le sÃ©mantique...
ğŸ“š 70 documents chargÃ©s depuis la FAQ

Recherche pour : Je veux changer de prÃ©nom, comment faire ?
Document trouvÃ© (Pertinence: 0.7823) : Question: Comment changer de prÃ©nom ? RÃ©ponse: Depuis 2017...
RÃ©ponse IA : Pour changer votre prÃ©nom, vous devez justifier d'un intÃ©rÃªt lÃ©gitime...
```

### Modifier la question de test

Ã‰ditez la derniÃ¨re ligne du fichier Python :

```python
if __name__ == "__main__":
    q = "Votre question ici"
    print("RÃ©ponse IA :", interroger_rag(q))
```

---

## ğŸ³ Utilisation avec Docker

### PrÃ©requis Docker

- **Docker** installÃ© ([Installation](https://docs.docker.com/get-docker/))
- **Docker Compose** installÃ© (inclus avec Docker Desktop)

### Lancer le projet avec Docker

1. **CrÃ©er le fichier `.env`** avec ton token Hugging Face :
   ```
   HF_TOKEN=votre_token_ici
   ```

2. **Construire et lancer le conteneur** :
   ```bash
   docker-compose up --build
   ```

3. **ArrÃªter le conteneur** :
   ```bash
   docker-compose down
   ```

### Commandes Docker utiles

```bash
# Lancer en arriÃ¨re-plan
docker-compose up -d

# Voir les logs
docker-compose logs -f

# ExÃ©cuter une commande dans le conteneur
docker-compose exec faq-assistant python -m src.strategies.strategie_a_llm_seul

# Reconstruire l'image
docker-compose build --no-cache
```

---

## ğŸ“Š DonnÃ©es

### `faq_base.json`

Base de connaissance de **70 questions-rÃ©ponses** organisÃ©es par catÃ©gories :
- Ã‰tat civil (mariages, naissances, dÃ©cÃ¨s)
- Urbanisme (permis de construire, dÃ©clarations)
- DÃ©chets et environnement
- Transports
- Petite enfance
- Social et solidaritÃ©
- Vie associative
- Ã‰lections
- Logement
- Culture et sport
- FiscalitÃ©
- Eau et assainissement

### `golden_set.json`

Jeu de test de **30 questions** pour Ã©valuer les stratÃ©gies :
- 10 questions directes (match exact avec la FAQ)
- 10 reformulations (mÃªme sens, mots diffÃ©rents)
- 5 questions hors sujet (test des garde-fous)
- 5 questions complexes (nÃ©cessitant plusieurs rÃ©ponses)

---

## ğŸ§ª Benchmark

Le protocole d'Ã©valuation compare les 3 stratÃ©gies sur :

| CritÃ¨re | Poids | Description |
|---------|-------|-------------|
| **Exactitude** | 40% | La rÃ©ponse contient les informations clÃ©s |
| **Pertinence** | 30% | La rÃ©ponse est utile pour l'usager |
| **Hallucinations** | 20% | Absence d'informations inventÃ©es |
| **Latence** | 10% | Temps de rÃ©ponse |

Les rÃ©sultats sont consignÃ©s dans `benchmark/GRILLE_EVALUATION.pdf`.

---

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Python 3.9+**
- **Hugging Face Inference API** (accÃ¨s aux modÃ¨les)
- **sentence-transformers** (embeddings sÃ©mantiques)
- **Meta-Llama-3-8B-Instruct** (gÃ©nÃ©ration de texte)
- **all-MiniLM-L6-v2** (embeddings, 384 dimensions)
- **roberta-base-squad2** (extraction de rÃ©ponse)

---

## ğŸ“– Documentation

- **PrÃ©sentation stratÃ©gique** : `docs/day_1/note_de_cadrage.pdf`
- **Rapport de veille technique** : `docs/day_1/rapport_veille_technique.pdf`
- **Protocole de benchmark** : `docs/day_2/protocole_benchmark.pdf`
- **Grille d'Ã©valuation** : `docs/day_2/grille_evaluation.pdf`

---

## ğŸ‘¤ Auteur

**Arnaud Rambourg**  
Projet rÃ©alisÃ© dans le cadre d'un stage en dÃ©veloppement IA pour collectivitÃ©s territoriales.

---

## ğŸ“ Licence

Projet Ã  usage pÃ©dagogique et dÃ©monstratif.

---

## ğŸ†˜ DÃ©pannage

### Erreur "HF_TOKEN not found"
VÃ©rifiez que le fichier `.env` existe Ã  la racine et contient :
```
HF_TOKEN=hf_xxxxxxxxxxxxx
```

### Erreur "Model is loading"
Le modÃ¨le Mistral peut Ãªtre indisponible sur l'API gratuite. Le projet utilise Llama 3 par dÃ©faut.

### TÃ©lÃ©chargement lent des modÃ¨les
Au premier lancement, `sentence-transformers` tÃ©lÃ©charge ~90 MB. C'est normal et ne se produit qu'une fois.

---

## ğŸš€ Prochaines Ã‰tapes

- [ ] ImplÃ©menter la StratÃ©gie C (Extractif)
- [ ] CrÃ©er le script de benchmark automatique
- [ ] DÃ©ployer l'assistant en production (API FastAPI)
- [ ] Interface utilisateur (Streamlit ou web)
